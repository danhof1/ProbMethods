{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import spacy   # another tokenizer, lemmatizer (has --> be)\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import inaugural\n",
        "nltk.download('inaugural')\n",
        "nltk.download('punkt')\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.disable_pipes('parser', 'ner')\n"
      ],
      "metadata": {
        "id": "AQfy0LkPxMsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dc8a703-69df-4e8b-a1e3-2bf57528036f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['parser', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get Docs"
      ],
      "metadata": {
        "id": "1p19rOnRGSMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list names inaugural addresses\n",
        "list_doc = inaugural.fileids()\n",
        "# methods inaugural object\n",
        "print(dir(inaugural))\n",
        "print(list_doc)"
      ],
      "metadata": {
        "id": "OdXB2LOWGMC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85eb1725-32e5-41b4-dab5-c06ffef59bf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CorpusView', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_citation', '_encoding', '_fileids', '_get_root', '_license', '_para_block_reader', '_read_para_block', '_read_sent_block', '_read_word_block', '_readme', '_root', '_sent_tokenizer', '_tagset', '_unload', '_word_tokenizer', 'abspath', 'abspaths', 'citation', 'encoding', 'ensure_loaded', 'fileids', 'license', 'open', 'paras', 'raw', 'readme', 'root', 'sents', 'words']\n",
            "['1789-Washington.txt', '1793-Washington.txt', '1797-Adams.txt', '1801-Jefferson.txt', '1805-Jefferson.txt', '1809-Madison.txt', '1813-Madison.txt', '1817-Monroe.txt', '1821-Monroe.txt', '1825-Adams.txt', '1829-Jackson.txt', '1833-Jackson.txt', '1837-VanBuren.txt', '1841-Harrison.txt', '1845-Polk.txt', '1849-Taylor.txt', '1853-Pierce.txt', '1857-Buchanan.txt', '1861-Lincoln.txt', '1865-Lincoln.txt', '1869-Grant.txt', '1873-Grant.txt', '1877-Hayes.txt', '1881-Garfield.txt', '1885-Cleveland.txt', '1889-Harrison.txt', '1893-Cleveland.txt', '1897-McKinley.txt', '1901-McKinley.txt', '1905-Roosevelt.txt', '1909-Taft.txt', '1913-Wilson.txt', '1917-Wilson.txt', '1921-Harding.txt', '1925-Coolidge.txt', '1929-Hoover.txt', '1933-Roosevelt.txt', '1937-Roosevelt.txt', '1941-Roosevelt.txt', '1945-Roosevelt.txt', '1949-Truman.txt', '1953-Eisenhower.txt', '1957-Eisenhower.txt', '1961-Kennedy.txt', '1965-Johnson.txt', '1969-Nixon.txt', '1973-Nixon.txt', '1977-Carter.txt', '1981-Reagan.txt', '1985-Reagan.txt', '1989-Bush.txt', '1993-Clinton.txt', '1997-Clinton.txt', '2001-Bush.txt', '2005-Bush.txt', '2009-Obama.txt', '2013-Obama.txt', '2017-Trump.txt', '2021-Biden.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_docs = []    # list of raw text documents\n",
        "for fid in list_doc:\n",
        "    list_docs.append(inaugural.raw(fid))\n",
        "\n",
        "print(len(list_docs))\n",
        "\n",
        "#print(name_doc)\n",
        "#print(list_docs[0])"
      ],
      "metadata": {
        "id": "QLIlal1mGZQ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41e2e53e-adb7-4ac9-ede5-801525da4b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# access the words\n",
        "# Print the first 100 words\n",
        "print(inaugural.words('1789-Washington.txt')[:20])\n",
        " # replace words with paras - get paragraphs"
      ],
      "metadata": {
        "id": "skvFZrwlGZZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8da0c00-4e65-4001-8c37-1f6bccb96f96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Fellow', '-', 'Citizens', 'of', 'the', 'Senate', 'and', 'of', 'the', 'House', 'of', 'Representatives', ':', 'Among', 'the', 'vicissitudes', 'incident', 'to', 'life', 'no']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Nc1r-B7hHgdz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nFRlXOcLHf3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer # extract words and count words in each text\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from collections import Counter\n",
        "\n",
        "import spacy   # another tokenizer, lemmatizer (has --> be)\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "up2qh7C_GZhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: text processing for one document - return lemmas\n",
        "def nlp_processing(doc):\n",
        "    tokens = nlp(doc)\n",
        "\n",
        "    #print(type(tokens))\n",
        "    # eliminates stop words  and non alpha num and converts all to lower case\n",
        "    terms = [token.lemma_.lower() for token in tokens if not token.is_stop and token.is_alpha]\n",
        "\n",
        "    return terms\n",
        "\n",
        "# Step 2: extract a list of (token, doc_id) from all documents.\n",
        "# input a list of documents\n",
        "# output: a list of sorted (token, doc_id) tuples\n",
        "def extract_token_doc_id(list_doc):\n",
        "  all_tokens = []\n",
        "  len_docs = [0]*len(list_doc)\n",
        "  for ind_doc, doc in enumerate(list_doc):\n",
        "    tokens = nlp_processing(inaugural.raw(doc))\n",
        "    len_docs[ind_doc] = len(tokens)\n",
        "    tokens_doc = [(token, ind_doc) for token in tokens]\n",
        "    all_tokens.extend(tokens_doc)\n",
        "\n",
        "  # sort by token name\n",
        "  all_tokens = sorted(all_tokens, key = lambda x:x[0])\n",
        "\n",
        "  return all_tokens, len_docs\n",
        "\n",
        "# count of each term in the collection\n",
        "def counter(items):\n",
        "  sort_items = sorted(items) # sorts tokens alphabetically\n",
        "  count_items = {}\n",
        "  for item in sort_items:\n",
        "    if item in count_items.keys():\n",
        "      count_items[item] += 1\n",
        "    else:\n",
        "      count_items[item] = 1\n",
        "\n",
        "  # sort by the count, in reverse order\n",
        "  sorted_count_list = sorted(count_items.items(),\n",
        "                            key = lambda x:x[1], reverse = True)\n",
        "  sorted_count_dict = dict(sorted_count_list)\n",
        "  return sorted_count_dict\n",
        "\n",
        "\n",
        "# Step 3: Extract terms (unique) and document frequency (count tokens)\n",
        "# change this to account only once for a repeated term in the same document\n",
        "# all_tokens list of tuples\n",
        "def doc_freq(all_tokens):\n",
        "  set_all_tokens = set(all_tokens) # remove duplicate token in the same document\n",
        "  dict_doc_freq = {}\n",
        "  for (token, doc) in set_all_tokens:\n",
        "    if token in dict_doc_freq:\n",
        "      dict_doc_freq[token] += 1\n",
        "    else:\n",
        "      dict_doc_freq[token] = 1\n",
        "\n",
        "  # sort by key (term)\n",
        "  tuples_doc_freq = sorted(dict_doc_freq.items(), key = lambda x: x[0])\n",
        "\n",
        "  dict_doc_freq = {term:doc_freq for (term, doc_freq) in tuples_doc_freq}\n",
        "  return dict_doc_freq\n",
        "\n",
        "# Step 4: Extract term frequency of each term in each document it appears in\n",
        "# dict_term_freq = {term: {doc1:tf1, doc2:tf2, ...}} # includes only docs that have\n",
        "# non-zero term frequency\n",
        "def term_freq(all_tokens, dict_doc_freq):\n",
        "  dict_term_freq = {term:{} for term in dict_doc_freq.keys()} # initialize dictionary with all unique terms\n",
        "  for (token, doc) in all_tokens:\n",
        "    if doc in dict_term_freq[token]:\n",
        "      dict_term_freq[token][doc] += 1\n",
        "    else: # if doc is not a key in the dictionary\n",
        "      dict_term_freq[token][doc] = 1\n",
        "\n",
        "  return dict_term_freq"
      ],
      "metadata": {
        "id": "AR1saorIxRfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nlp processing on all docs, extract len_docs\n",
        "list_token_doc, len_docs = extract_token_doc_id(list_doc)\n",
        "print(list_token_doc[:5])\n",
        "print(len_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XAtHFpI5d9Z",
        "outputId": "55089c52-4404-4487-d0e0-ee95a3d5c459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('abandon', 2), ('abandon', 3), ('abandon', 8), ('abandon', 8), ('abandon', 11)]\n",
            "[578, 56, 976, 723, 902, 478, 501, 1388, 1795, 1245, 490, 486, 1670, 3297, 2033, 487, 1416, 1218, 1411, 283, 465, 532, 1088, 1303, 749, 1904, 916, 1691, 952, 382, 2325, 703, 575, 1557, 1667, 1554, 831, 812, 547, 224, 1051, 1103, 702, 609, 581, 877, 728, 504, 986, 1123, 947, 677, 943, 681, 925, 1029, 891, 618, 1004]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the P(w|collection) = count of a word in the collection/sum length docs\n",
        "len_collection = sum(len_docs)\n",
        "all_tokens = [t for (t,d) in list_token_doc]\n",
        "dict_collection = counter(all_tokens) # count of each word in the collection as a sorted dictionary\n",
        "print(list(dict_collection.items())[:5])\n",
        "print(list(dict_collection.items())[-5:])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcvGvCqJ5zQk",
        "outputId": "c3338cd4-d0f3-4f93-944b-1f5a17f451d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('government', 651), ('people', 633), ('nation', 517), ('great', 441), ('country', 359)]\n",
            "[('wrongfully', 1), ('yearn', 1), ('yearning', 1), ('youthful', 1), ('zone', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_term_freq = term_freq(list_token_doc, dict_collection)\n",
        "print(list(dict_term_freq.items())[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuElP9pB7wxz",
        "outputId": "4667696e-8b49-47e0-dc46-5cd3994de69a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('government', {0: 9, 1: 1, 2: 18, 3: 13, 4: 3, 6: 3, 7: 22, 8: 15, 9: 21, 10: 8, 11: 14, 12: 17, 13: 44, 14: 50, 15: 8, 16: 10, 17: 14, 18: 19, 19: 1, 20: 3, 21: 5, 22: 20, 23: 24, 24: 17, 25: 11, 26: 14, 27: 24, 28: 16, 29: 3, 30: 28, 31: 9, 32: 1, 33: 14, 34: 16, 35: 30, 36: 4, 37: 16, 38: 4, 40: 4, 41: 1, 43: 1, 44: 1, 45: 5, 46: 10, 47: 4, 48: 16, 49: 20, 50: 5, 51: 4, 52: 10, 53: 4, 54: 6, 55: 4, 56: 4, 57: 3}), ('people', {0: 4, 1: 1, 2: 20, 3: 2, 5: 1, 6: 3, 7: 15, 8: 11, 9: 7, 10: 4, 11: 9, 12: 20, 13: 38, 14: 16, 15: 3, 16: 6, 17: 13, 18: 20, 20: 2, 21: 7, 22: 9, 23: 21, 24: 18, 25: 29, 26: 22, 27: 25, 28: 12, 29: 6, 30: 7, 31: 2, 32: 8, 33: 12, 34: 16, 35: 18, 36: 8, 37: 11, 38: 9, 39: 2, 40: 21, 41: 18, 42: 15, 43: 2, 44: 9, 45: 15, 46: 6, 47: 7, 48: 9, 49: 17, 50: 7, 51: 12, 52: 11, 53: 1, 54: 7, 55: 8, 56: 11, 57: 10, 58: 10}), ('nation', {0: 3, 2: 20, 3: 4, 4: 6, 5: 8, 6: 5, 7: 10, 8: 10, 9: 15, 10: 2, 11: 2, 12: 7, 13: 7, 14: 8, 15: 2, 16: 12, 17: 11, 19: 4, 20: 6, 21: 5, 22: 9, 23: 13, 24: 3, 25: 10, 26: 2, 27: 4, 28: 6, 29: 7, 30: 7, 31: 6, 32: 9, 33: 11, 34: 17, 35: 17, 36: 6, 37: 11, 38: 15, 39: 1, 40: 19, 41: 9, 42: 17, 43: 6, 44: 13, 45: 8, 46: 14, 47: 14, 48: 7, 49: 5, 50: 12, 51: 5, 52: 15, 53: 13, 54: 11, 55: 15, 56: 8, 57: 11, 58: 14}), ('great', {0: 4, 2: 5, 3: 4, 4: 1, 6: 1, 7: 25, 8: 29, 9: 9, 10: 1, 11: 4, 12: 9, 13: 28, 14: 7, 15: 2, 16: 8, 17: 12, 18: 6, 19: 1, 20: 6, 21: 6, 22: 10, 23: 14, 24: 4, 25: 15, 26: 1, 27: 19, 28: 6, 29: 5, 30: 12, 31: 14, 32: 5, 33: 7, 34: 19, 35: 9, 36: 5, 37: 6, 38: 3, 39: 1, 40: 8, 41: 3, 42: 7, 43: 1, 44: 6, 45: 7, 46: 10, 47: 2, 48: 9, 49: 7, 50: 12, 51: 3, 52: 10, 53: 4, 54: 6, 55: 5, 56: 5, 57: 6, 58: 7}), ('country', {0: 5, 1: 1, 2: 10, 3: 4, 4: 5, 5: 5, 6: 6, 7: 11, 8: 8, 9: 10, 10: 2, 11: 3, 12: 17, 13: 25, 14: 19, 15: 6, 16: 6, 17: 9, 18: 3, 20: 8, 21: 8, 22: 20, 23: 2, 24: 4, 25: 7, 26: 4, 27: 15, 28: 3, 29: 1, 30: 12, 31: 1, 33: 5, 34: 20, 35: 9, 36: 1, 37: 3, 38: 1, 39: 1, 40: 11, 41: 7, 42: 1, 43: 4, 44: 1, 45: 1, 46: 3, 47: 1, 48: 3, 49: 1, 50: 3, 51: 1, 53: 9, 54: 8, 55: 2, 56: 7, 57: 12, 58: 4})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# jm similarity method\n",
        "import numpy as np\n",
        "\n",
        "def jm_similarity(query, len_docs, dict_freq_collection, dict_term_freq,\n",
        "                  lam = 0.2):\n",
        "  # process the query - > word and count in the query\n",
        "  query_terms = nlp_processing(query)\n",
        "  dict_freq_query = counter(query_terms)\n",
        "  words_query = dict_freq_query.keys()\n",
        "\n",
        "  # find the set of docs with at least 1 query word\n",
        "  len_all = sum(len_docs) # length of the collection\n",
        "  docs = []\n",
        "\n",
        "  for w in words_query:\n",
        "    docs.extend(dict_term_freq[w].keys())\n",
        "  docs = set(docs)\n",
        "\n",
        "  similarity = {d:0 for d in docs}\n",
        "\n",
        "  # for each word in the query\n",
        "  for w in words_query:\n",
        "  #   for each doc the word appears in\n",
        "    if w not in dict_freq_collection: # if word does not appear in the collection skip over it\n",
        "      continue\n",
        "    # check the documents w appears in\n",
        "    for d in docs:\n",
        "      # compute P(w|d) = (1-lambda) * c(w,d)/len(d) + lambda*c(w,C)/sum(len)\n",
        "      c_w_d = 0\n",
        "      if d in dict_term_freq[w]:\n",
        "        c_w_d = dict_term_freq[w][d]\n",
        "\n",
        "      prob_w_d = (1-lam)* c_w_d/len_docs[d] + (lam*dict_freq_collection[w])/len_all\n",
        "\n",
        "      # add to the similarity of (q,d) =  c(w,q) * log(P(w|d)\n",
        "      similarity[d] += dict_freq_query[w] * np.log(prob_w_d)\n",
        "\n",
        "  # sort the similarity by value\n",
        "  sorted_sim = sorted(similarity.items(), key = lambda x: x[1], reverse = True)\n",
        "  return sorted_sim"
      ],
      "metadata": {
        "id": "6gaJ9vIz8n4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dirchlet_similarity(query, len_docs, dict_freq_collection, dict_term_freq,\n",
        "                  mu = 0.2):\n",
        "  # process the query - > word and count in the query\n",
        "  query_terms = nlp_processing(query)\n",
        "  dict_freq_query = counter(query_terms)\n",
        "  words_query = dict_freq_query.keys()\n",
        "\n",
        "  # find the set of docs with at least 1 query word\n",
        "  len_all = sum(len_docs) # length of the collection\n",
        "  docs = []\n",
        "\n",
        "  for w in words_query:\n",
        "    docs.extend(dict_term_freq[w].keys())\n",
        "  docs = set(docs)\n",
        "\n",
        "  similarity = {d:0 for d in docs}\n",
        "\n",
        "  # for each word in the query\n",
        "  for w in words_query:\n",
        "  #   for each doc the word appears in\n",
        "    if w not in dict_freq_collection: # if word does not appear in the collection skip over it\n",
        "      continue\n",
        "    # check the documents w appears in\n",
        "    for d in docs:\n",
        "      # compute P(w|d) = (1-lambda) * c(w,d)/len(d) + lambda*c(w,C)/sum(len)\n",
        "      c_w_d = 0\n",
        "      if d in dict_term_freq[w]:\n",
        "        c_w_d = dict_term_freq[w][d]\n",
        "\n",
        "      #prob_w_d = (1-lam)* c_w_d/len_docs[d] + (lam*dict_freq_collection[w])/len_all\n",
        "      prob_w_d = (c_w_d+mu*dict_freq_collection[w])/(len_docs[d]+mu)\n",
        "\n",
        "      # add to the similarity of (q,d) =  c(w,q) * log(P(w|d)\n",
        "      similarity[d] += dict_freq_query[w] * np.log(prob_w_d)\n",
        "\n",
        "  # sort the similarity by value\n",
        "  sorted_sim = sorted(similarity.items(), key = lambda x: x[1], reverse = True)\n",
        "  return sorted_sim"
      ],
      "metadata": {
        "id": "w-e1c-s0SpID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getTupple(ranked_doc,list_doc):\n",
        "  # Retrieve the second value from each tuple\n",
        "  doc_ids = [x[0] for x in ranked_doc]\n",
        "  return (list_doc[doc_ids[0]],list_doc[doc_ids[1]],list_doc[doc_ids[2]])"
      ],
      "metadata": {
        "id": "bQWf4NZdPMa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"jm_similarity and smoothiung\\n\")\n",
        "\n",
        "ranked_doc = jm_similarity(\"economic growth policy\", len_docs, dict_collection, dict_term_freq, 0.3)\n",
        "print(f\"Top 3 Similarity for \\\"economic growth policy\\\" with smoothing .3 \\n {ranked_doc[:3]}\")\n",
        "print(f\"Associated Titles{getTupple(ranked_doc,list_doc)}\")\n",
        "print(f\"Precision Value {3/3}\\n\")\n",
        "\n",
        "ranked_doc = jm_similarity(\"economic growth policy\", len_docs, dict_collection, dict_term_freq, 0.7)\n",
        "print(f\"Top 3 Similarity Similarity for \\\"economic growth policy\\\" with smoothing .7 \\n {ranked_doc[:3]}\")\n",
        "print(f\"Associated Titles{getTupple(ranked_doc,list_doc)}\")\n",
        "print(f\"Precision Value {3/3}\\n\")\n",
        "\n",
        "ranked_doc = jm_similarity(\"national security defense\", len_docs, dict_collection, dict_term_freq, 0.3)\n",
        "print(f\"Top 3 Similarity Similarity for \\\"national security defense\\\" with smoothing .3 \\n {ranked_doc[:3]}\")\n",
        "print(f\"Associated Titles{getTupple(ranked_doc,list_doc)}\")\n",
        "print(f\"Precision Value {3/3}\\n\")\n",
        "\n",
        "ranked_doc = jm_similarity(\"national security defense\", len_docs, dict_collection, dict_term_freq, 0.7)\n",
        "print(f\"Top 3 Similarity Similarity for \\\"national security defense\\\" with smoothing .7 \\n {ranked_doc[:3]}\")\n",
        "print(f\"Associated Titles{getTupple(ranked_doc,list_doc)}\")\n",
        "print(f\"Precision Value {3/3}\\n\")\n",
        "\n",
        "ranked_doc = jm_similarity(\"god bless america\", len_docs, dict_collection, dict_term_freq, 0.3)\n",
        "print(f\"Top 3 Similarity Similarity for \\\"god bless america\\\" with smoothing .3 \\n {ranked_doc[:3]}\")\n",
        "print(f\"Associated Titles{getTupple(ranked_doc,list_doc)}\")\n",
        "print(f\"Precision Value {3/3}\\n\")\n",
        "\n",
        "ranked_doc = jm_similarity(\"god bless america\", len_docs, dict_collection, dict_term_freq, 0.7)\n",
        "print(f\"Top 3 Similarity Similarity for \\\"god bless america\\\" with smoothing .7 \\n {ranked_doc[:3]}\")\n",
        "print(f\"Associated Titles{getTupple(ranked_doc,list_doc)}\")\n",
        "print(f\"Precision Value {3/3}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T1PQeZ8B-1c",
        "outputId": "e1ecde0a-d523-4b50-b219-d8f55946043a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jm_similarity and smoothiung\n",
            "\n",
            "Top 3 Similarity for \"economic growth policy\" with smoothing .3 \n",
            " [(35, -18.574836780395568), (40, -19.26070813237846), (49, -19.544314985274454)]\n",
            "Associated Titles('1929-Hoover.txt', '1949-Truman.txt', '1985-Reagan.txt')\n",
            "Precision Value 1.0\n",
            "\n",
            "Top 3 Similarity Similarity for \"economic growth policy\" with smoothing .7 \n",
            " [(35, -19.584579246824976), (49, -19.77231245487262), (40, -19.858900627391694)]\n",
            "Associated Titles('1929-Hoover.txt', '1985-Reagan.txt', '1949-Truman.txt')\n",
            "Precision Value 1.0\n",
            "\n",
            "Top 3 Similarity Similarity for \"national security defense\" with smoothing .3 \n",
            " [(40, -17.01965322063667), (49, -17.741735654457493), (9, -17.978621694256972)]\n",
            "Associated Titles('1949-Truman.txt', '1985-Reagan.txt', '1825-Adams.txt')\n",
            "Precision Value 1.0\n",
            "\n",
            "Top 3 Similarity Similarity for \"national security defense\" with smoothing .7 \n",
            " [(40, -18.083309771406142), (49, -18.672308092841725), (9, -18.783942311290573)]\n",
            "Associated Titles('1949-Truman.txt', '1985-Reagan.txt', '1825-Adams.txt')\n",
            "Precision Value 1.0\n",
            "\n",
            "Top 3 Similarity Similarity for \"god bless america\" with smoothing .3 \n",
            " [(57, -14.445426101589039), (53, -16.09472637778715), (39, -16.14323560220687)]\n",
            "Associated Titles('2017-Trump.txt', '2001-Bush.txt', '1945-Roosevelt.txt')\n",
            "Precision Value 1.0\n",
            "\n",
            "Top 3 Similarity Similarity for \"god bless america\" with smoothing .7 \n",
            " [(57, -16.239430473853773), (39, -17.34669250666402), (53, -17.444646226496157)]\n",
            "Associated Titles('2017-Trump.txt', '1945-Roosevelt.txt', '2001-Bush.txt')\n",
            "Precision Value 1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comment on the results you got with respect to lambda, and the best results you obtained with the vector space method"
      ],
      "metadata": {
        "id": "kMsIVxywEGBH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### When putting in lambda values 0.3 and 0.7 for the jm_similarity function, there was a very clear distinction that we observed between the two values, in which the lower lambda score of 0.3 gave a much better similarity value that was closer to 0 than the higher lambda score of 0.7. Furthermore, both lambda values gave an output of 1.0 precison values for the queries, meaning that all top documents were found to be relevant to the query. For example, for the query \"god bless America\", we observed that although the top 3 ranked documents were the same for both lambda values, the similarity scores for lambda value 0.3 was -14.45, -16.09, and -16.14 while the similarity scores for lambda value 0.7 was higher being -16.24, -17.35, and -17.445. This was the case with all queries when tested with lambda values 0.3 and 0.7 so therefore we had concluded that the lambda value of 0.3 provides a better similarity score for the documents. The best results that we obtained from the vector space method were for the \"god bless America\" query, since we had gotten the lowest similarity scores."
      ],
      "metadata": {
        "id": "ChpkiFfAELXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "\n",
        "def getMu(list_doc):\n",
        "  length_arr =[]\n",
        "  for doc in list_doc:\n",
        "    length_arr.append(len(inaugural.raw(doc)))\n",
        "  mean = sum(length_arr)/len(length_arr)\n",
        "  std_dev_sample = statistics.stdev(length_arr)\n",
        "  return (mean, std_dev_sample)"
      ],
      "metadata": {
        "id": "ApaWp1lWWM7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"dirchlet and smoothiung\\n\")\n",
        "\n",
        "Mu = getMu(list_doc)\n",
        "\n",
        "print(Mu)\n",
        "\n",
        "\n",
        "ranked_doc = dirchlet_similarity(\"economic growth policy\", len_docs, dict_collection, dict_term_freq, Mu[0])\n",
        "print(f\"Top 3 Similarity for \\\"economic growth policy\\\" with smoothing based on mean \\n {ranked_doc[:3]}\")\n",
        "print(f\"Associated Titles{getTupple(ranked_doc,list_doc)}\")\n",
        "print(f\"Precision Value {2/3}\\n\")\n",
        "\n",
        "ranked_doc = dirchlet_similarity(\"economic growth policy\", len_docs, dict_collection, dict_term_freq, Mu[1])\n",
        "print(f\"Top 3 Similarity Similarity for \\\"economic growth policy\\\" with smoothing based on std_dev \\n {ranked_doc[:3]}\")\n",
        "print(f\"Associated Titles{getTupple(ranked_doc,list_doc)}\")\n",
        "print(f\"Precision Value {2/3}\\n\")\n",
        "\n",
        "ranked_doc = dirchlet_similarity(\"national security defense\", len_docs, dict_collection, dict_term_freq, Mu[0])\n",
        "print(f\"Top 3 Similarity Similarity for \\\"national security defense\\\" with smoothing based on mean \\n {ranked_doc[:3]}\")\n",
        "print(f\"Associated Titles{getTupple(ranked_doc,list_doc)}\")\n",
        "print(f\"Precision Value {1/3}\\n\")\n",
        "\n",
        "ranked_doc = dirchlet_similarity(\"national security defense\", len_docs, dict_collection, dict_term_freq, Mu[1])\n",
        "print(f\"Top 3 Similarity Similarity for \\\"national security defense\\\" with smoothing based on std_dev \\n {ranked_doc[:3]}\")\n",
        "print(f\"Associated Titles{getTupple(ranked_doc,list_doc)}\")\n",
        "print(f\"Precision Value {1/3}\\n\")\n",
        "\n",
        "ranked_doc = dirchlet_similarity(\"god bless america\", len_docs, dict_collection, dict_term_freq, Mu[0])\n",
        "print(f\"Top 3 Similarity Similarity for \\\"god bless america\\\" with smoothing based on mean \\n {ranked_doc[:3]}\")\n",
        "print(f\"Associated Titles{getTupple(ranked_doc,list_doc)}\")\n",
        "print(f\"Precision Value {3/3}\\n\")\n",
        "\n",
        "ranked_doc = dirchlet_similarity(\"god bless america\", len_docs, dict_collection, dict_term_freq, Mu[1])\n",
        "print(f\"Top 3 Similarity Similarity for \\\"god bless america\\\" with smoothing based on std_dev \\n {ranked_doc[:3]}\")\n",
        "print(f\"Associated Titles{getTupple(ranked_doc,list_doc)}\")\n",
        "print(f\"Precision Value {3/3}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJ4vOBiRSafO",
        "outputId": "fa3ed203-b8a6-4562-d34a-b6321fa185d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dirchlet and smoothiung\n",
            "\n",
            "(13682.64406779661, 8207.46889406168)\n",
            "Top 3 Similarity for \"economic growth policy\" with smoothing based on mean \n",
            " [(29, 11.877620590870288), (20, 11.859964719106703), (5, 11.857211311213392)]\n",
            "Associated Titles('1905-Roosevelt.txt', '1869-Grant.txt', '1809-Madison.txt')\n",
            "Precision Value 0.6666666666666666\n",
            "\n",
            "Top 3 Similarity Similarity for \"economic growth policy\" with smoothing based on std_dev \n",
            " [(29, 11.82375498379379), (20, 11.794898596195072), (5, 11.790408256650917)]\n",
            "Associated Titles('1905-Roosevelt.txt', '1869-Grant.txt', '1809-Madison.txt')\n",
            "Precision Value 0.6666666666666666\n",
            "\n",
            "Top 3 Similarity Similarity for \"national security defense\" with smoothing based on mean \n",
            " [(29, 13.173664737937806), (20, 13.15601435773037), (5, 13.15325742736077)]\n",
            "Associated Titles('1905-Roosevelt.txt', '1869-Grant.txt', '1809-Madison.txt')\n",
            "Precision Value 0.3333333333333333\n",
            "\n",
            "Top 3 Similarity Similarity for \"national security defense\" with smoothing based on std_dev \n",
            " [(29, 13.119796265539442), (20, 13.090949032880204), (5, 13.086452821031909)]\n",
            "Associated Titles('1905-Roosevelt.txt', '1869-Grant.txt', '1809-Madison.txt')\n",
            "Precision Value 0.3333333333333333\n",
            "\n",
            "Top 3 Similarity Similarity for \"god bless america\" with smoothing based on mean \n",
            " [(1, 13.708331348750148), (39, 13.671872383426354), (19, 13.65917178428056)]\n",
            "Associated Titles('1793-Washington.txt', '1945-Roosevelt.txt', '1865-Lincoln.txt')\n",
            "Precision Value 1.0\n",
            "\n",
            "Top 3 Similarity Similarity for \"god bless america\" with smoothing based on std_dev \n",
            " [(1, 13.700185183957558), (39, 13.639811219216988), (19, 13.618891889580375)]\n",
            "Associated Titles('1793-Washington.txt', '1945-Roosevelt.txt', '1865-Lincoln.txt')\n",
            "Precision Value 1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comment on the results with respect to the value of mu, and to the results with the JM smoothing and the best results with the vector space method."
      ],
      "metadata": {
        "id": "3yoYB1fbD89J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### When testing with the value of mu we decided to base the value of mu on the mean length of the documents and the standard deviation of the documents to see which one would display better results. The precision values were the same among the respective queries, in which both the mean and standard deviation produced the same precision value, where the query \"economic growth policy\" had a precision value of 0.66, \"national security defense\" had a precision value 0.33, and \"god bless America\" had a precision value of 1. Additionally, we observed that the mean value outputted better similarity scores than the standard deviation value, in which the values weren't that much greater but it was still recognizable that the mean value performed better with the dirchlet function. When comparing the results from the jm_similarity function and the results from the dirchlet function we found the jm_similarity function to be much more precise with relevancy than the dirchlet function since the precision values for the jm_similarity output were all 1 and the precision values for the dirchlet function ranged from 0.6 for the \"economic growth policy\" query, to 0.3 for the \"national security defense\" query, to 1.0 for the \"god bless America\" query. Once again, the best results found with the vector space method were for the \"god bless America\" query, where we got the highest values from the mean value being 13.71, 13.67, and 13.66."
      ],
      "metadata": {
        "id": "d4YFx9c7OP_a"
      }
    }
  ]
}